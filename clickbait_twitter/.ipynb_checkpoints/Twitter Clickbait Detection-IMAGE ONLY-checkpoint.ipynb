{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "C297HhYulXcb",
    "outputId": "d6e2a9df-586e-4192-b8ec-1e7b7025c0c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "fVPglpaf4REa",
    "outputId": "eef4a4ca-e12d-4cd3-e011-20376fc752a2"
   },
   "outputs": [],
   "source": [
    "data0 = pd.read_csv('clickbait_new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "4hARIXyGKorc",
    "outputId": "bc223e7f-4529-4ebe-e7d0-7eef13e691c0"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-5-aa0f22a60d12>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-aa0f22a60d12>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    ''''\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#Checking the shape of the dataset\n",
    "''''\n",
    "data0 = data0.drop(['postMedia'], axis = 1).copy()\n",
    "data0 = data0.drop(['postText'], axis = 1).copy()\n",
    "data0 = data0.drop(['id'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetCaptions'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetParagraphs'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetTitle'], axis = 1).copy()\n",
    "data0 = data0.drop(['postTimestamp'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetKeywords'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetDescription'], axis = 1).copy()\n",
    "data0 = data0.drop(['Unnamed: 0'], axis = 1).copy()\n",
    "''''\n",
    "data = data0.drop(data0.iloc[:, 1:2048], axis = 1) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truthClass</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>2.1</th>\n",
       "      <th>3.1</th>\n",
       "      <th>4.1</th>\n",
       "      <th>5.1</th>\n",
       "      <th>6.1</th>\n",
       "      <th>7.1</th>\n",
       "      <th>8.1</th>\n",
       "      <th>...</th>\n",
       "      <th>758.1</th>\n",
       "      <th>759.1</th>\n",
       "      <th>760.1</th>\n",
       "      <th>761.1</th>\n",
       "      <th>762.1</th>\n",
       "      <th>763.1</th>\n",
       "      <th>764.1</th>\n",
       "      <th>765.1</th>\n",
       "      <th>766.1</th>\n",
       "      <th>767.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.688721</td>\n",
       "      <td>-0.311484</td>\n",
       "      <td>0.210605</td>\n",
       "      <td>0.466656</td>\n",
       "      <td>0.064158</td>\n",
       "      <td>0.221654</td>\n",
       "      <td>-0.366249</td>\n",
       "      <td>0.806478</td>\n",
       "      <td>-0.187936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062446</td>\n",
       "      <td>-0.228487</td>\n",
       "      <td>-0.247298</td>\n",
       "      <td>0.192776</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>0.372195</td>\n",
       "      <td>-0.402308</td>\n",
       "      <td>-0.503938</td>\n",
       "      <td>0.271705</td>\n",
       "      <td>-0.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>-0.531985</td>\n",
       "      <td>-0.416530</td>\n",
       "      <td>0.275493</td>\n",
       "      <td>-0.202287</td>\n",
       "      <td>0.044897</td>\n",
       "      <td>-0.367996</td>\n",
       "      <td>-0.144052</td>\n",
       "      <td>0.708746</td>\n",
       "      <td>0.184805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181490</td>\n",
       "      <td>-0.168663</td>\n",
       "      <td>0.091808</td>\n",
       "      <td>-0.132993</td>\n",
       "      <td>0.436112</td>\n",
       "      <td>-0.178089</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>-0.262597</td>\n",
       "      <td>0.586113</td>\n",
       "      <td>-0.298647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.487721</td>\n",
       "      <td>-0.107452</td>\n",
       "      <td>0.448648</td>\n",
       "      <td>-0.023562</td>\n",
       "      <td>0.137262</td>\n",
       "      <td>-0.355240</td>\n",
       "      <td>0.151737</td>\n",
       "      <td>0.330627</td>\n",
       "      <td>-0.373410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292704</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>-0.168034</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>-0.124418</td>\n",
       "      <td>0.155721</td>\n",
       "      <td>-0.527867</td>\n",
       "      <td>-0.406164</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>0.407489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>-0.083074</td>\n",
       "      <td>-0.161080</td>\n",
       "      <td>-0.676829</td>\n",
       "      <td>0.086798</td>\n",
       "      <td>0.887813</td>\n",
       "      <td>-0.590393</td>\n",
       "      <td>-0.100112</td>\n",
       "      <td>0.880795</td>\n",
       "      <td>-0.126271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308586</td>\n",
       "      <td>0.254039</td>\n",
       "      <td>-0.053593</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.222441</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>-0.415741</td>\n",
       "      <td>-0.749960</td>\n",
       "      <td>-0.127007</td>\n",
       "      <td>-0.021985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.292251</td>\n",
       "      <td>-0.431718</td>\n",
       "      <td>0.381722</td>\n",
       "      <td>-0.323031</td>\n",
       "      <td>0.450927</td>\n",
       "      <td>-0.294065</td>\n",
       "      <td>0.427811</td>\n",
       "      <td>0.327797</td>\n",
       "      <td>-0.538308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>-0.051631</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.381170</td>\n",
       "      <td>0.027305</td>\n",
       "      <td>-0.365211</td>\n",
       "      <td>-0.521021</td>\n",
       "      <td>0.230563</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     truthClass       0.1       1.1       2.1       3.1       4.1       5.1  \\\n",
       "0  no-clickbait  0.688721 -0.311484  0.210605  0.466656  0.064158  0.221654   \n",
       "1     clickbait -0.531985 -0.416530  0.275493 -0.202287  0.044897 -0.367996   \n",
       "2     clickbait  0.487721 -0.107452  0.448648 -0.023562  0.137262 -0.355240   \n",
       "3  no-clickbait -0.083074 -0.161080 -0.676829  0.086798  0.887813 -0.590393   \n",
       "4     clickbait  0.292251 -0.431718  0.381722 -0.323031  0.450927 -0.294065   \n",
       "\n",
       "        6.1       7.1       8.1  ...     758.1     759.1     760.1     761.1  \\\n",
       "0 -0.366249  0.806478 -0.187936  ... -0.062446 -0.228487 -0.247298  0.192776   \n",
       "1 -0.144052  0.708746  0.184805  ... -0.181490 -0.168663  0.091808 -0.132993   \n",
       "2  0.151737  0.330627 -0.373410  ... -0.292704  0.025508 -0.168034 -0.005331   \n",
       "3 -0.100112  0.880795 -0.126271  ... -0.308586  0.254039 -0.053593  0.049524   \n",
       "4  0.427811  0.327797 -0.538308  ...  0.015432 -0.051631 -0.307450  0.044342   \n",
       "\n",
       "      762.1     763.1     764.1     765.1     766.1     767.1  \n",
       "0  0.219171  0.372195 -0.402308 -0.503938  0.271705 -0.182700  \n",
       "1  0.436112 -0.178089  0.262557 -0.262597  0.586113 -0.298647  \n",
       "2 -0.124418  0.155721 -0.527867 -0.406164 -0.186023  0.407489  \n",
       "3  0.222441  0.144363 -0.415741 -0.749960 -0.127007 -0.021985  \n",
       "4  0.381170  0.027305 -0.365211 -0.521021  0.230563  0.041473  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = data0.drop(data0.iloc[:, 1:2048], axis = 1) \n",
    "data = data.drop('2047', axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data0['truthClass'] = le.fit_transform(data0['truthClass'])\n",
    "data = data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "4LZnaoU_qBsz",
    "outputId": "df212692-ea66-4d67-a4aa-00a256010f69"
   },
   "outputs": [],
   "source": [
    "# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "FzEU-wcLN8K7",
    "outputId": "534f9839-31e6-4b19-b469-c16db57fd5a9"
   },
   "outputs": [],
   "source": [
    "# Sepratating & assigning features and target columns to X & y\n",
    "y = data['truthClass']\n",
    "X = data.drop(['truthClass'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected=fs.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "84xKobSqAV3U",
    "outputId": "20c0a9f7-d20e-4176-f815-238727c44336"
   },
   "source": [
    "# Splitting the dataset into train and test sets: 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "1kzsjtudy-0w",
    "outputId": "80b84eba-eeb1-48d1-d95a-412b7cfb4c45"
   },
   "source": [
    "# Decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth = 5)\n",
    "#tree.fit(X_train, y_train)\n",
    "#y_pred_dc = tree.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), tree)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "2fmB9rPSsR6y",
    "outputId": "27ddebf4-bee1-4eec-eb4e-995d4cdc08b2"
   },
   "source": [
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "#forest.fit(X_train, y_train)\n",
    "#y_pred_rf = forest.predict(X_test)\n",
    "#print('Random Forest: ' + (str)(accuracy_score(y_test,y_pred_rf)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), forest)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "JSFAbsgnAxqv",
    "outputId": "2828ce2e-95ec-4dfd-e7dd-5d3da152ea09"
   },
   "source": [
    "# Multilayer Perceptrons model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
    "#mlp.fit(X_train, y_train)\n",
    "#y_pred_mlp = mlp.predict(X_test)\n",
    "#print('MLP: ' + (str)(accuracy_score(y_test,y_pred_mlp)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), mlp)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "oIIQGzxgAREc",
    "outputId": "fc27da07-7071-4fbf-9d05-05e514ad9b3e"
   },
   "source": [
    "#XGBoost Classification model\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "#xgb.fit(X_train, y_train)\n",
    "#y_pred_xgb = xgb.predict(X_test)\n",
    "#print('XGB: ' + (str)(accuracy_score(y_test,y_pred_xgb)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), xgb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AdaBoost Classification model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(learning_rate=0.4,random_state=7)\n",
    "#ada.fit(X_train, y_train)\n",
    "#y_pred_ada = ada.predict(X_test)\n",
    "#print('ADA: ' + (str)(accuracy_score(y_test,y_pred_ada)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), ada)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate=0.4,max_depth=7)\n",
    "#gb.fit(X_train, y_train)\n",
    "#y_pred_gb = gb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), gb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(learning_rate=0.4, depth=7)\n",
    "#cat.fit(X_train, y_train)\n",
    "#y_pred_cat = cat.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), cat)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "#lor.fit(X_train, y_train)\n",
    "#y_pred_lor = lor.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), lor)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb=BernoulliNB()\n",
    "#bnb.fit(X_train, y_train)\n",
    "#y_pred_bnb = bnb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), bnb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "#gnb.fit(X_train, y_train)\n",
    "#y_pred_gnb = gnb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), gnb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=12)\n",
    "#svm.fit(X_train, y_train)\n",
    "#y_pred_svm = svm.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict = {'Decision Tree':y_pred_dc, 'Random Forest':y_pred_rf, 'MLP':y_pred_mlp, 'XGB':y_pred_xgb, 'ADA':y_pred_ada,'Gradient Boost':y_pred_gb, 'Cat Boost':y_pred_cat, 'Log Reg':y_pred_lor, 'Bern NB': y_pred_bnb, 'Gaussian NB':y_pred_gnb, 'SVM':y_pred_svm, 'Label':y_test}\n",
    "df1 = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y1 = df1['Label']\n",
    "X1 = df1.drop(['Label'],axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state = 12)\n",
    "X1_train.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "forest.fit(X1_train, y1_train)\n",
    "y1_test_forest = forest.predict(X1_test)\n",
    "acc1_test_forest = accuracy_score(y1_test,y1_test_forest)\n",
    "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc1_test_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statistics import mode\n",
    "from sklearn.metrics import accuracy_score \n",
    "y_pred_maj = []\n",
    "for i in range(y_pred_xgb.size):\n",
    "    y_maj = []\n",
    "    y_maj.append(y_pred_dc[i])\n",
    "    y_maj.append(y_pred_rf[i])\n",
    "    y_maj.append(y_pred_mlp[i])\n",
    "    y_maj.append(y_pred_xgb[i])\n",
    "    y_maj.append(y_pred_ada[i])\n",
    "    y_maj.append(y_pred_gb[i])\n",
    "    y_maj.append(y_pred_cat[i])\n",
    "    y_maj.append(y_pred_lor[i])\n",
    "    y_maj.append(y_pred_bnb[i])\n",
    "    y_maj.append(y_pred_gnb[i])\n",
    "    y_maj.append(y_pred_svm[i])\n",
    "    y_pred_maj.append(mode(y_maj))\n",
    "print(accuracy_score(y_test,y_pred_maj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Decision Tree: ' + (str)(accuracy_score(y_test,y_pred_dc)))\n",
    "print('Random Forest: ' + (str)(accuracy_score(y_test,y_pred_rf)))\n",
    "print('MLP: ' + (str)(accuracy_score(y_test,y_pred_mlp)))\n",
    "print('XGB: ' + (str)(accuracy_score(y_test,y_pred_xgb)))\n",
    "print('ADA: ' + (str)(accuracy_score(y_test,y_pred_ada)))\n",
    "print('Gradient Boost: ' + (str)(accuracy_score(y_test,y_pred_gb)))\n",
    "print('Cat Boost: ' + (str)(accuracy_score(y_test,y_pred_cat)))\n",
    "print('Log Reg: ' + (str)(accuracy_score(y_test,y_pred_lor)))\n",
    "print('Bern NB: ' + (str)(accuracy_score(y_test,y_pred_bnb)))\n",
    "print('Gaussian NB: ' + (str)(accuracy_score(y_test,y_pred_gnb)))\n",
    "print('SVM: ' + (str)(accuracy_score(y_test,y_pred_svm)))\n",
    "print(\"Random forest Stacking: \" + (str)(acc1_test_forest))\n",
    "print('Majority Voting: ' + (str)(accuracy_score(y_test,y_pred_maj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), model)\n",
    "    scores = cross_val_score(clf,X,y, cv = 5)\n",
    "    return scores\n",
    "\n",
    "def get_stacking():\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('xgb', XGBClassifier(learning_rate=0.4,max_depth=7)))\n",
    "    level0.append(('svm', SVC(kernel='linear', C=1.0, random_state=12)))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    level1 = forest = RandomForestClassifier(max_depth=5)\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "stacking_model = get_stacking()\n",
    "print (evaluate_model(stacking_model, X_selected, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statistics import mean, stdev \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import linear_model \n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) \n",
    "lst_accu_stratified = [] \n",
    "scaler = preprocessing.MinMaxScaler() \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "x_scaled = scaler.fit_transform(X_selected)\n",
    "for train_index, test_index in skf.split(X_selected, y): \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index] \n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index] \n",
    "    lor.fit(x_train_fold, y_train_fold) \n",
    "    y_pred_fold = lor.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(lor.score(x_test_fold, y_test_fold))\n",
    "print('List of possible accuracy:', lst_accu_stratified) \n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:', \n",
    "      max(lst_accu_stratified)*100, '%') \n",
    "print('\\nMinimum Accuracy:', \n",
    "      min(lst_accu_stratified)*100, '%') \n",
    "print('\\nOverall Accuracy:', \n",
    "      mean(lst_accu_stratified)*100, '%') \n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print(classification_report(y_test_fold, y_pred_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = GaussianNB()\n",
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf4 = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "clf5 = SVC(kernel='linear', C=1.0, random_state=12)\n",
    "forest = RandomForestClassifier(max_depth=7)\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                            meta_classifier=forest,\n",
    "                            random_state=42)\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "          'logisticregression__C': [0.1, 10.0],\n",
    "          'meta_classifier__n_estimators': [200, 500],\n",
    "          'meta_classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'meta_classifier__max_depth' : [4,5,6,7,8],\n",
    "          'meta_classifier__criterion' : ['gini', 'entropy']}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)    \n",
    "y_true, y_pred = y_test, grid.predict(X_test)   \n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "acc = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy: \", acc)\n",
    "print(\"\\n\")\n",
    "print(f\"AUC of stack {combo}: {auc:.3f}\")\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected1=fs.fit_transform(X,y)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    clf = make_pipeline(StandardScaler(), model)\n",
    "    scores = cross_val_score(clf,X,y, cv = 5)\n",
    "    return scores\n",
    "\n",
    "def get_stacking():\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('xgb', XGBClassifier(learning_rate=0.4,max_depth=7)))\n",
    "    level0.append(('svm', SVC(kernel='linear', C=1.0, random_state=12)))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    level1 = forest = RandomForestClassifier(max_depth=5)\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "stacking_model = get_stacking()\n",
    "print (evaluate_model(stacking_model, X_selected1, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected1, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator = stacking_model.final_estimator, \n",
    "                    param_grid = params, \n",
    "                    cv = 5,\n",
    "                    scoring = \"roc_auc\",\n",
    "                    verbose = 10,\n",
    "                    n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict_proba(X_test)[:,1]\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(f\"The AUC of the tuned Stacking classifier is {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected = fs.fit_transform(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = GaussianNB()\n",
    "clf2 = LogisticRegression(C=10.0, max_iter=10000)\n",
    "clf4 = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "clf5 = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
    "#clf6 = SVC(kernel='linear', C=1.0, random_state=12, probability=True)\n",
    "forest = RandomForestClassifier(max_depth=4, max_features='sqrt', n_estimators=200, criterion='entropy')\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                            meta_classifier=forest,\n",
    "                            random_state=42,\n",
    "                            cv=5)\n",
    "classifiers = {\"KNN\": clf1,\n",
    "               \"LR\": clf2,\n",
    "               \"NB\": clf3,\n",
    "               \"XGBoost\": clf4,\n",
    "               \"MLP\" : clf5,\n",
    "               \"Stack\": sclf}\n",
    "\n",
    "for key in classifiers:\n",
    "    classifier = classifiers[key]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifiers[key] = classifier\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for key in classifiers:\n",
    "    y_pred = classifiers[key].predict_proba(X_test)[:,1]\n",
    "    results[f\"{key}\"] = y_pred\n",
    "\n",
    "results[\"Target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf, label in zip([sclf], \n",
    "                      [\n",
    "                          'StackingClassifier']):\n",
    "\n",
    "    scoring1 = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    scores = model_selection.cross_validate(clf, X, y, \n",
    "                                              cv=5, scoring=scoring1)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf, label in zip([sclf], \n",
    "                      ['StackingClassifier']):\n",
    "\n",
    "    scoring1 = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    scores = model_selection.cross_validate(clf, X, y, \n",
    "                                              cv=5, scoring=scoring1)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Phishing Website Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
