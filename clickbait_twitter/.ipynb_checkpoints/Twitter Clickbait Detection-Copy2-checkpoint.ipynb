{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "C297HhYulXcb",
    "outputId": "d6e2a9df-586e-4192-b8ec-1e7b7025c0c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "fVPglpaf4REa",
    "outputId": "eef4a4ca-e12d-4cd3-e011-20376fc752a2"
   },
   "outputs": [],
   "source": [
    "data0 = pd.read_csv('clickbait_new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "4hARIXyGKorc",
    "outputId": "bc223e7f-4529-4ebe-e7d0-7eef13e691c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truthClass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758.1</th>\n",
       "      <th>759.1</th>\n",
       "      <th>760.1</th>\n",
       "      <th>761.1</th>\n",
       "      <th>762.1</th>\n",
       "      <th>763.1</th>\n",
       "      <th>764.1</th>\n",
       "      <th>765.1</th>\n",
       "      <th>766.1</th>\n",
       "      <th>767.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403262</td>\n",
       "      <td>0.380966</td>\n",
       "      <td>0.097885</td>\n",
       "      <td>0.915787</td>\n",
       "      <td>0.518525</td>\n",
       "      <td>0.054882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062446</td>\n",
       "      <td>-0.228487</td>\n",
       "      <td>-0.247298</td>\n",
       "      <td>0.192776</td>\n",
       "      <td>0.219171</td>\n",
       "      <td>0.372195</td>\n",
       "      <td>-0.402308</td>\n",
       "      <td>-0.503938</td>\n",
       "      <td>0.271705</td>\n",
       "      <td>-0.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.604051</td>\n",
       "      <td>1.577550</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065148</td>\n",
       "      <td>0.108716</td>\n",
       "      <td>0.092904</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.133231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181490</td>\n",
       "      <td>-0.168663</td>\n",
       "      <td>0.091808</td>\n",
       "      <td>-0.132993</td>\n",
       "      <td>0.436112</td>\n",
       "      <td>-0.178089</td>\n",
       "      <td>0.262557</td>\n",
       "      <td>-0.262597</td>\n",
       "      <td>0.586113</td>\n",
       "      <td>-0.298647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>1.694349</td>\n",
       "      <td>0.385032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300371</td>\n",
       "      <td>0.112176</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.413344</td>\n",
       "      <td>4.049719</td>\n",
       "      <td>0.610870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292704</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>-0.168034</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>-0.124418</td>\n",
       "      <td>0.155721</td>\n",
       "      <td>-0.527867</td>\n",
       "      <td>-0.406164</td>\n",
       "      <td>-0.186023</td>\n",
       "      <td>0.407489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>no-clickbait</td>\n",
       "      <td>0.565944</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>1.439137</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.193930</td>\n",
       "      <td>0.042614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308586</td>\n",
       "      <td>0.254039</td>\n",
       "      <td>-0.053593</td>\n",
       "      <td>0.049524</td>\n",
       "      <td>0.222441</td>\n",
       "      <td>0.144363</td>\n",
       "      <td>-0.415741</td>\n",
       "      <td>-0.749960</td>\n",
       "      <td>-0.127007</td>\n",
       "      <td>-0.021985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>clickbait</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.163362</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>1.903011</td>\n",
       "      <td>0.239372</td>\n",
       "      <td>0.007409</td>\n",
       "      <td>0.150233</td>\n",
       "      <td>0.191606</td>\n",
       "      <td>2.429517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>-0.051631</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.381170</td>\n",
       "      <td>0.027305</td>\n",
       "      <td>-0.365211</td>\n",
       "      <td>-0.521021</td>\n",
       "      <td>0.230563</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     truthClass         0         1         2         3         4         5  \\\n",
       "0  no-clickbait  0.000000  0.000000  0.000000  0.403262  0.380966  0.097885   \n",
       "1     clickbait  1.604051  1.577550  0.022459  0.000000  0.065148  0.108716   \n",
       "2     clickbait  1.694349  0.385032  0.000000  1.300371  0.112176  0.032497   \n",
       "3  no-clickbait  0.565944  0.010859  1.439137  0.006216  0.010878  0.000000   \n",
       "4     clickbait  0.783740  0.163362  0.006691  1.903011  0.239372  0.007409   \n",
       "\n",
       "          6         7         8  ...     758.1     759.1     760.1     761.1  \\\n",
       "0  0.915787  0.518525  0.054882  ... -0.062446 -0.228487 -0.247298  0.192776   \n",
       "1  0.092904  0.010695  0.133231  ... -0.181490 -0.168663  0.091808 -0.132993   \n",
       "2  0.413344  4.049719  0.610870  ... -0.292704  0.025508 -0.168034 -0.005331   \n",
       "3  0.000234  0.193930  0.042614  ... -0.308586  0.254039 -0.053593  0.049524   \n",
       "4  0.150233  0.191606  2.429517  ...  0.015432 -0.051631 -0.307450  0.044342   \n",
       "\n",
       "      762.1     763.1     764.1     765.1     766.1     767.1  \n",
       "0  0.219171  0.372195 -0.402308 -0.503938  0.271705 -0.182700  \n",
       "1  0.436112 -0.178089  0.262557 -0.262597  0.586113 -0.298647  \n",
       "2 -0.124418  0.155721 -0.527867 -0.406164 -0.186023  0.407489  \n",
       "3  0.222441  0.144363 -0.415741 -0.749960 -0.127007 -0.021985  \n",
       "4  0.381170  0.027305 -0.365211 -0.521021  0.230563  0.041473  \n",
       "\n",
       "[5 rows x 2817 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the dataset\n",
    "data0 = data0.drop(['postMedia'], axis = 1).copy()\n",
    "data0 = data0.drop(['postText'], axis = 1).copy()\n",
    "data0 = data0.drop(['id'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetCaptions'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetParagraphs'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetTitle'], axis = 1).copy()\n",
    "data0 = data0.drop(['postTimestamp'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetKeywords'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetDescription'], axis = 1).copy()\n",
    "data0 = data0.drop(['Unnamed: 0'], axis = 1).copy()\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data0['truthClass'] = le.fit_transform(data0['truthClass'])\n",
    "data = data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "4LZnaoU_qBsz",
    "outputId": "df212692-ea66-4d67-a4aa-00a256010f69"
   },
   "outputs": [],
   "source": [
    "# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "FzEU-wcLN8K7",
    "outputId": "534f9839-31e6-4b19-b469-c16db57fd5a9"
   },
   "outputs": [],
   "source": [
    "# Sepratating & assigning features and target columns to X & y\n",
    "y = data['truthClass']\n",
    "X = data.drop(['truthClass'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected=fs.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "84xKobSqAV3U",
    "outputId": "20c0a9f7-d20e-4176-f815-238727c44336"
   },
   "source": [
    "# Splitting the dataset into train and test sets: 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "1kzsjtudy-0w",
    "outputId": "80b84eba-eeb1-48d1-d95a-412b7cfb4c45"
   },
   "source": [
    "# Decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth = 5)\n",
    "#tree.fit(X_train, y_train)\n",
    "#y_pred_dc = tree.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), tree)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "2fmB9rPSsR6y",
    "outputId": "27ddebf4-bee1-4eec-eb4e-995d4cdc08b2"
   },
   "source": [
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "#forest.fit(X_train, y_train)\n",
    "#y_pred_rf = forest.predict(X_test)\n",
    "#print('Random Forest: ' + (str)(accuracy_score(y_test,y_pred_rf)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), forest)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "JSFAbsgnAxqv",
    "outputId": "2828ce2e-95ec-4dfd-e7dd-5d3da152ea09"
   },
   "source": [
    "# Multilayer Perceptrons model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
    "#mlp.fit(X_train, y_train)\n",
    "#y_pred_mlp = mlp.predict(X_test)\n",
    "#print('MLP: ' + (str)(accuracy_score(y_test,y_pred_mlp)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), mlp)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "oIIQGzxgAREc",
    "outputId": "fc27da07-7071-4fbf-9d05-05e514ad9b3e"
   },
   "source": [
    "#XGBoost Classification model\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "#xgb.fit(X_train, y_train)\n",
    "#y_pred_xgb = xgb.predict(X_test)\n",
    "#print('XGB: ' + (str)(accuracy_score(y_test,y_pred_xgb)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), xgb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#AdaBoost Classification model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(learning_rate=0.4,random_state=7)\n",
    "#ada.fit(X_train, y_train)\n",
    "#y_pred_ada = ada.predict(X_test)\n",
    "#print('ADA: ' + (str)(accuracy_score(y_test,y_pred_ada)))\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), ada)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(learning_rate=0.4,max_depth=7)\n",
    "#gb.fit(X_train, y_train)\n",
    "#y_pred_gb = gb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), gb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(learning_rate=0.4, depth=7)\n",
    "#cat.fit(X_train, y_train)\n",
    "#y_pred_cat = cat.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), cat)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "#lor.fit(X_train, y_train)\n",
    "#y_pred_lor = lor.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), lor)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb=BernoulliNB()\n",
    "#bnb.fit(X_train, y_train)\n",
    "#y_pred_bnb = bnb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), bnb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "#gnb.fit(X_train, y_train)\n",
    "#y_pred_gnb = gnb.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), gnb)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=12)\n",
    "#svm.fit(X_train, y_train)\n",
    "#y_pred_svm = svm.predict(X_test)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm)\n",
    "scores = cross_val_score(clf,X_selected,y, cv = 5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict = {'Decision Tree':y_pred_dc, 'Random Forest':y_pred_rf, 'MLP':y_pred_mlp, 'XGB':y_pred_xgb, 'ADA':y_pred_ada,'Gradient Boost':y_pred_gb, 'Cat Boost':y_pred_cat, 'Log Reg':y_pred_lor, 'Bern NB': y_pred_bnb, 'Gaussian NB':y_pred_gnb, 'SVM':y_pred_svm, 'Label':y_test}\n",
    "df1 = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y1 = df1['Label']\n",
    "X1 = df1.drop(['Label'],axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state = 12)\n",
    "X1_train.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "forest.fit(X1_train, y1_train)\n",
    "y1_test_forest = forest.predict(X1_test)\n",
    "acc1_test_forest = accuracy_score(y1_test,y1_test_forest)\n",
    "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc1_test_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statistics import mode\n",
    "from sklearn.metrics import accuracy_score \n",
    "y_pred_maj = []\n",
    "for i in range(y_pred_xgb.size):\n",
    "    y_maj = []\n",
    "    y_maj.append(y_pred_dc[i])\n",
    "    y_maj.append(y_pred_rf[i])\n",
    "    y_maj.append(y_pred_mlp[i])\n",
    "    y_maj.append(y_pred_xgb[i])\n",
    "    y_maj.append(y_pred_ada[i])\n",
    "    y_maj.append(y_pred_gb[i])\n",
    "    y_maj.append(y_pred_cat[i])\n",
    "    y_maj.append(y_pred_lor[i])\n",
    "    y_maj.append(y_pred_bnb[i])\n",
    "    y_maj.append(y_pred_gnb[i])\n",
    "    y_maj.append(y_pred_svm[i])\n",
    "    y_pred_maj.append(mode(y_maj))\n",
    "print(accuracy_score(y_test,y_pred_maj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Decision Tree: ' + (str)(accuracy_score(y_test,y_pred_dc)))\n",
    "print('Random Forest: ' + (str)(accuracy_score(y_test,y_pred_rf)))\n",
    "print('MLP: ' + (str)(accuracy_score(y_test,y_pred_mlp)))\n",
    "print('XGB: ' + (str)(accuracy_score(y_test,y_pred_xgb)))\n",
    "print('ADA: ' + (str)(accuracy_score(y_test,y_pred_ada)))\n",
    "print('Gradient Boost: ' + (str)(accuracy_score(y_test,y_pred_gb)))\n",
    "print('Cat Boost: ' + (str)(accuracy_score(y_test,y_pred_cat)))\n",
    "print('Log Reg: ' + (str)(accuracy_score(y_test,y_pred_lor)))\n",
    "print('Bern NB: ' + (str)(accuracy_score(y_test,y_pred_bnb)))\n",
    "print('Gaussian NB: ' + (str)(accuracy_score(y_test,y_pred_gnb)))\n",
    "print('SVM: ' + (str)(accuracy_score(y_test,y_pred_svm)))\n",
    "print(\"Random forest Stacking: \" + (str)(acc1_test_forest))\n",
    "print('Majority Voting: ' + (str)(accuracy_score(y_test,y_pred_maj)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    clf = make_pipeline(preprocessing.StandardScaler(), model)\n",
    "    scores = cross_val_score(clf,X,y, cv = 5)\n",
    "    return scores\n",
    "\n",
    "def get_stacking():\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('xgb', XGBClassifier(learning_rate=0.4,max_depth=7)))\n",
    "    level0.append(('svm', SVC(kernel='linear', C=1.0, random_state=12)))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    level1 = forest = RandomForestClassifier(max_depth=5)\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "stacking_model = get_stacking()\n",
    "print (evaluate_model(stacking_model, X_selected, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statistics import mean, stdev \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import linear_model \n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) \n",
    "lst_accu_stratified = [] \n",
    "scaler = preprocessing.MinMaxScaler() \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "x_scaled = scaler.fit_transform(X_selected)\n",
    "for train_index, test_index in skf.split(X_selected, y): \n",
    "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index] \n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index] \n",
    "    lor.fit(x_train_fold, y_train_fold) \n",
    "    y_pred_fold = lor.predict(x_test_fold)\n",
    "    lst_accu_stratified.append(lor.score(x_test_fold, y_test_fold))\n",
    "print('List of possible accuracy:', lst_accu_stratified) \n",
    "print('\\nMaximum Accuracy That can be obtained from this model is:', \n",
    "      max(lst_accu_stratified)*100, '%') \n",
    "print('\\nMinimum Accuracy:', \n",
    "      min(lst_accu_stratified)*100, '%') \n",
    "print('\\nOverall Accuracy:', \n",
    "      mean(lst_accu_stratified)*100, '%') \n",
    "print('\\nStandard Deviation is:', stdev(lst_accu_stratified))\n",
    "print(classification_report(y_test_fold, y_pred_fold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = GaussianNB()\n",
    "clf2 = LogisticRegression(max_iter=1000)\n",
    "clf4 = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "clf5 = SVC(kernel='linear', C=1.0, random_state=12)\n",
    "forest = RandomForestClassifier(max_depth=7)\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5], \n",
    "                            meta_classifier=forest,\n",
    "                            random_state=42)\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 5],\n",
    "          'logisticregression__C': [0.1, 10.0],\n",
    "          'meta_classifier__n_estimators': [200, 500],\n",
    "          'meta_classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'meta_classifier__max_depth' : [4,5,6,7,8],\n",
    "          'meta_classifier__criterion' : ['gini', 'entropy']}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid.best_params_)    \n",
    "y_true, y_pred = y_test, grid.predict(X_test)   \n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "acc = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"\\nAccuracy: \", acc)\n",
    "print(\"\\n\")\n",
    "print(f\"AUC of stack {combo}: {auc:.3f}\")\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "print('Best parameters: %s' % grid.best_params_)\n",
    "print('Accuracy: %.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected1=fs.fit_transform(X,y)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    clf = make_pipeline(StandardScaler(), model)\n",
    "    scores = cross_val_score(clf,X,y, cv = 5)\n",
    "    return scores\n",
    "\n",
    "def get_stacking():\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('xgb', XGBClassifier(learning_rate=0.4,max_depth=7)))\n",
    "    level0.append(('svm', SVC(kernel='linear', C=1.0, random_state=12)))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    level1 = forest = RandomForestClassifier(max_depth=5)\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "stacking_model = get_stacking()\n",
    "print (evaluate_model(stacking_model, X_selected1, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected1, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator = stacking_model.final_estimator, \n",
    "                    param_grid = params, \n",
    "                    cv = 5,\n",
    "                    scoring = \"roc_auc\",\n",
    "                    verbose = 10,\n",
    "                    n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict_proba(X_test)[:,1]\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(f\"The AUC of the tuned Stacking classifier is {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X_selected = fs.fit_transform(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf3 = GaussianNB()\n",
    "clf2 = LogisticRegression(C=10.0, max_iter=10000)\n",
    "clf4 = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "clf5 = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
    "clf6 = SVC(kernel='linear', C=1.0, random_state=12, probability=True)\n",
    "forest = RandomForestClassifier(max_depth=4, max_features='sqrt', n_estimators=200, criterion='entropy')\n",
    "\n",
    "sclf = StackingCVClassifier(classifiers=[clf1, clf2, clf3, clf4, clf5, clf6], \n",
    "                            meta_classifier=forest,\n",
    "                            random_state=42,\n",
    "                            cv=5)\n",
    "classifiers = {\"KNN\": clf1,\n",
    "               \"LR\": clf2,\n",
    "               \"NB\": clf3,\n",
    "               \"XGBoost\": clf4,\n",
    "               \"MLP\" : clf5,\n",
    "               \"SVM\" : clf6 ,\n",
    "               \"Stack\": sclf}\n",
    "\n",
    "for key in classifiers:\n",
    "    classifier = classifiers[key]\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifiers[key] = classifier\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for key in classifiers:\n",
    "    y_pred = classifiers[key].predict_proba(X_test)[:,1]\n",
    "    results[f\"{key}\"] = y_pred\n",
    "\n",
    "results[\"Target\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([11.65698695,  6.17392302,  5.44825292,  4.10524321,  3.01532173]), 'score_time': array([307.86837077, 302.37808061, 231.53308296, 200.11720085,\n",
      "       166.9360342 ]), 'test_accuracy': array([0.73811833, 0.72246482, 0.7151868 , 0.70742358, 0.73022804]), 'test_precision': array([0.81828909, 0.80946746, 0.80593472, 0.80443911, 0.81796407]), 'test_recall': array([0.85670167, 0.84548826, 0.83930779, 0.82880099, 0.84425216]), 'test_f1': array([0.83705492, 0.82708585, 0.82228277, 0.81643836, 0.83090024]), 'test_roc_auc': array([0.58072104, 0.55931298, 0.5505794 , 0.54645467, 0.57901096])}\n",
      "{'fit_time': array([58.18385386, 83.21679211, 98.4259882 , 95.03555894, 58.43866491]), 'score_time': array([0.08148599, 0.09360671, 0.08661675, 0.08260798, 0.0897491 ]), 'test_accuracy': array([0.78031038, 0.78311499, 0.75497331, 0.77292576, 0.77244056]), 'test_precision': array([0.86346633, 0.86940063, 0.86491803, 0.87483703, 0.86662412]), 'test_recall': array([0.85546634, 0.85166873, 0.81520396, 0.82941904, 0.83930779]), 'test_f1': array([0.85944772, 0.86044333, 0.83932549, 0.85152284, 0.85274725]), 'test_roc_auc': array([0.76274335, 0.75974575, 0.73947437, 0.77020232, 0.749082  ])}\n",
      "{'fit_time': array([0.92478299, 0.84117103, 0.84780312, 0.8466692 , 0.84714317]), 'score_time': array([0.26677084, 0.2280848 , 0.22756791, 0.22712183, 0.22822404]), 'test_accuracy': array([0.71774976, 0.713246  , 0.71858321, 0.71664241, 0.74041727]), 'test_precision': array([0.8553804 , 0.84766418, 0.85991678, 0.86357243, 0.87682672]), 'test_recall': array([0.7708462 , 0.77379481, 0.76637824, 0.75896168, 0.77873918]), 'test_f1': array([0.81091618, 0.80904685, 0.81045752, 0.80789474, 0.82487725]), 'test_roc_auc': array([0.6781511 , 0.66995873, 0.68488045, 0.69581974, 0.73086845])}\n",
      "{'fit_time': array([193.11146998, 238.19114232, 243.02490711, 281.52550793,\n",
      "       285.61884904]), 'score_time': array([0.70244312, 0.86999297, 0.81467414, 1.04232597, 1.18775129]), 'test_accuracy': array([0.83802134, 0.83939835, 0.82920912, 0.84327996, 0.83891315]), 'test_precision': array([0.85674625, 0.8565097 , 0.85722348, 0.86437817, 0.8600224 ]), 'test_recall': array([0.95305744, 0.95550062, 0.93881335, 0.94932015, 0.94932015]), 'test_f1': array([0.90233918, 0.9033012 , 0.89616519, 0.90486009, 0.90246769]), 'test_roc_auc': array([0.84801601, 0.8527088 , 0.8278502 , 0.85931898, 0.85481198])}\n",
      "{'fit_time': array([ 93.807585  , 106.86084771,  84.95620513,  92.57884789,\n",
      "        80.86057377]), 'score_time': array([0.17920828, 0.19717002, 0.17181993, 0.26100993, 0.17359519]), 'test_accuracy': array([0.81910766, 0.81174187, 0.81077147, 0.82338671, 0.80931587]), 'test_precision': array([0.8547836 , 0.87272727, 0.86547619, 0.84262295, 0.87692308]), 'test_recall': array([0.9271155 , 0.88998764, 0.8986403 , 0.95302843, 0.88071693]), 'test_f1': array([0.88948148, 0.88127295, 0.88174651, 0.89443155, 0.87881591]), 'test_roc_auc': array([0.79437116, 0.81512443, 0.81084275, 0.80440836, 0.81257621])}\n",
      "{'fit_time': array([824.95726204, 859.14634919, 771.73575401, 835.36375499,\n",
      "       759.53069019]), 'score_time': array([43.28527379, 39.94030476, 32.63104892, 39.97113705, 32.60351992]), 'test_accuracy': array([0.77400582, 0.77244056, 0.7486657 , 0.76855895, 0.76419214]), 'test_precision': array([0.85963818, 0.86850545, 0.86375661, 0.87409836, 0.86375321]), 'test_recall': array([0.85114268, 0.8368356 , 0.80716934, 0.82385661, 0.83065513]), 'test_f1': array([0.85536934, 0.85237646, 0.83450479, 0.84823417, 0.84688091]), 'test_roc_auc': array([0.75540248, 0.75394894, 0.73415191, 0.76345961, 0.74358933])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, sclf], \n",
    "                      ['KNN', \n",
    "                       'Logistic Regression', \n",
    "                       'Gaussian Naive Bayes',\n",
    "                       'XGBoost',\n",
    "                       'MLP',\n",
    "                       'SVM',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scoring1 = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    scores = model_selection.cross_validate(clf, X, y, \n",
    "                                              cv=5, scoring=scoring1)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf, label in zip([sclf], \n",
    "                      ['StackingClassifier']):\n",
    "\n",
    "    scoring1 = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    scores = model_selection.cross_validate(clf, X, y, \n",
    "                                              cv=5, scoring=scoring1)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "f, ax = plt.subplots(figsize=(13, 4), nrows=1, ncols = 5)\n",
    "for key, counter in zip(classifiers, range(5)):\n",
    "    y_pred = results[key]\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    textstr = f\"AUC: {auc:.3f}\"\n",
    "    false_pred = results[results[\"Target\"] == 0]\n",
    "    sns.distplot(false_pred[key], hist=True, kde=False, \n",
    "                 bins=int(25), color = 'hotpink',\n",
    "                 hist_kws={'edgecolor':'black'}, ax = ax[counter])\n",
    "    true_pred = results[results[\"Target\"] == 1]\n",
    "    sns.distplot(results[key], hist=True, kde=False, \n",
    "                 bins=int(25), color = 'dodgerblue',\n",
    "                 hist_kws={'edgecolor':'black'}, ax = ax[counter])\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "    ax[counter].text(0.05, 0.95, textstr, transform=ax[counter].transAxes, fontsize=14,\n",
    "                    verticalalignment = \"top\", bbox=props)\n",
    "    ax[counter].set_title(f\"{key} Distribution\")\n",
    "    ax[counter].set_xlim(0,1)\n",
    "    ax[counter].set_xlabel(\"Probability\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,20))\n",
    "n_features = X_train.shape[1]\n",
    "plt.barh(range(n_features), forest.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(n_features), X_train.columns)\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "plt.savefig('plotx.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Phishing Website Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
