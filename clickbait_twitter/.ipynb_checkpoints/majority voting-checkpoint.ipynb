{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "C297HhYulXcb",
    "outputId": "d6e2a9df-586e-4192-b8ec-1e7b7025c0c3"
   },
   "outputs": [],
   "source": [
    "#importing basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "fVPglpaf4REa",
    "outputId": "eef4a4ca-e12d-4cd3-e011-20376fc752a2"
   },
   "outputs": [],
   "source": [
    "data0 = pd.read_csv('clickbait_new_data.csv')\n",
    "#Checking the shape of the dataset\n",
    "data0 = data0.drop(['postMedia'], axis = 1).copy()\n",
    "data0 = data0.drop(['postText'], axis = 1).copy()\n",
    "data0 = data0.drop(['id'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetCaptions'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetParagraphs'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetTitle'], axis = 1).copy()\n",
    "data0 = data0.drop(['postTimestamp'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetKeywords'], axis = 1).copy()\n",
    "data0 = data0.drop(['targetDescription'], axis = 1).copy()\n",
    "data0 = data0.drop(['Unnamed: 0'], axis = 1).copy()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data0['truthClass'] = le.fit_transform(data0['truthClass'])\n",
    "data = data0\n",
    "# shuffling the rows in the dataset so that when splitting the train and test set are equally distributed\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "# Sepratating & assigning features and target columns to X & y\n",
    "y = data['truthClass']\n",
    "X = data.drop(['truthClass'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "84xKobSqAV3U",
    "outputId": "20c0a9f7-d20e-4176-f815-238727c44336"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "fs = SelectKBest(score_func=f_classif, k=200)\n",
    "X = fs.fit_transform(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, random_state = 12)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "D5Tg_ei0-xPU"
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "1kzsjtudy-0w",
    "outputId": "80b84eba-eeb1-48d1-d95a-412b7cfb4c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate the model \n",
    "tree = DecisionTreeClassifier(max_depth = 5)\n",
    "# fit the model \n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cpPk7O-MrTZi"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_tree = tree.predict(X_test)\n",
    "y_train_tree = tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree=tree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "X4wDTnFZrz3q",
    "outputId": "a8bf5873-8185-4f18-e0f0-87717975e5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Accuracy on training Data: 0.837\n",
      "Decision Tree: Accuracy on test Data: 0.797\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_tree = accuracy_score(y_train,y_train_tree)\n",
    "acc_test_tree = accuracy_score(y_test,y_test_tree)\n",
    "\n",
    "print(\"Decision Tree: Accuracy on training Data: {:.3f}\".format(acc_train_tree))\n",
    "print(\"Decision Tree: Accuracy on test Data: {:.3f}\".format(acc_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "2fmB9rPSsR6y",
    "outputId": "27ddebf4-bee1-4eec-eb4e-995d4cdc08b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate the model\n",
    "forest = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "# fit the model \n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "J1Qck-wrsabB"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_forest = forest.predict(X_test)\n",
    "y_train_forest = forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_forest = forest.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "Oguf-37tsboO",
    "outputId": "34386ec6-a7f0-4185-b3c0-a40de3239fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: Accuracy on training Data: 0.837\n",
      "Random forest: Accuracy on test Data: 0.809\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_forest = accuracy_score(y_train,y_train_forest)\n",
    "acc_test_forest = accuracy_score(y_test,y_test_forest)\n",
    "\n",
    "print(\"Random forest: Accuracy on training Data: {:.3f}\".format(acc_train_forest))\n",
    "print(\"Random forest: Accuracy on test Data: {:.3f}\".format(acc_test_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ_EW8QUC0bn"
   },
   "source": [
    "### **7.3. Multilayer Perceptrons (MLPs): Deep Learning**\n",
    "Multilayer perceptrons (MLPs) are also known as (vanilla) feed-forward neural networks, or sometimes just neural networks. Multilayer perceptrons can be applied for both classification and regression problems.\n",
    "\n",
    "MLPs can be viewed as generalizations of linear models that perform multiple stages of processing to come to a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "JSFAbsgnAxqv",
    "outputId": "2828ce2e-95ec-4dfd-e7dd-5d3da152ea09"
   },
   "outputs": [],
   "source": [
    "# Multilayer Perceptrons model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# instantiate the model\n",
    "mlp = MLPClassifier(alpha=0.001, hidden_layer_sizes=([100,100,100]))\n",
    "\n",
    "# fit the model \n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyuSg6w_A4pN"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_mlp = mlp.predict(X_test)\n",
    "y_train_mlp = mlp.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = mlp.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "z2ndgKQbA64_",
    "outputId": "40ddef62-9dd4-4d55-b5ba-9932ba07a0b5"
   },
   "outputs": [],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_mlp = accuracy_score(y_train,y_train_mlp)\n",
    "acc_test_mlp = accuracy_score(y_test,y_test_mlp)\n",
    "\n",
    "print(\"Multilayer Perceptrons: Accuracy on training Data: {:.3f}\".format(acc_train_mlp))\n",
    "print(\"Multilayer Perceptrons: Accuracy on test Data: {:.3f}\".format(acc_test_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVuTty-KaS4c"
   },
   "source": [
    "### **7.4. XGBoost Classifier**\n",
    "XGBoost is one of the most popular machine learning algorithms these days. XGBoost stands for eXtreme Gradient Boosting. Regardless of the type of prediction task at hand; regression or classification. XGBoost is an implementation of gradient boosted decision trees designed for speed and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "oIIQGzxgAREc",
    "outputId": "fc27da07-7071-4fbf-9d05-05e514ad9b3e"
   },
   "outputs": [],
   "source": [
    "#XGBoost Classification model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# instantiate the model\n",
    "xgb = XGBClassifier(learning_rate=0.4,max_depth=7)\n",
    "#fit the model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fx9xbzfAUO-"
   },
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_xgb = xgb.predict(X_test)\n",
    "y_train_xgb = xgb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "x1NNeI-NaxCA",
    "outputId": "d021057e-e9bc-487d-b584-9fb2492305de"
   },
   "outputs": [],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_xgb = accuracy_score(y_train,y_train_xgb)\n",
    "acc_test_xgb = accuracy_score(y_test,y_test_xgb)\n",
    "\n",
    "print(\"XGBoost: Accuracy on training Data: {:.3f}\".format(acc_train_xgb))\n",
    "print(\"XGBoost : Accuracy on test Data: {:.3f}\".format(acc_test_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classification model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# instantiate the model\n",
    "ada = AdaBoostClassifier(learning_rate=0.4,random_state=7)\n",
    "#fit the model\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "y_test_ada = ada.predict(X_test)\n",
    "y_train_ada = ada.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the accuracy of the model performance\n",
    "acc_train_ada = accuracy_score(y_train,y_train_ada)\n",
    "acc_test_ada = accuracy_score(y_test,y_test_ada)\n",
    "\n",
    "print(\"AdaBoost: Accuracy on training Data: {:.3f}\".format(acc_train_ada))\n",
    "print(\"AdaBoost : Accuracy on test Data: {:.3f}\".format(acc_test_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classification model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# instantiate the model\n",
    "gb = GradientBoostingClassifier(learning_rate=0.4,max_depth=7)\n",
    "#fit the model\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "#predicting the target value from the model for the samples\n",
    "y_test_gb = gb.predict(X_test)\n",
    "y_train_gb = gb.predict(X_train)\n",
    "\n",
    "#computing the accuracy of the model performance\n",
    "acc_train_gb = accuracy_score(y_train,y_train_gb)\n",
    "acc_test_gb = accuracy_score(y_test,y_test_gb)\n",
    "\n",
    "print(\"Gradient Boost: Accuracy on training Data: {:.3f}\".format(acc_train_gb))\n",
    "print(\"Gradient Boost : Accuracy on test Data: {:.3f}\".format(acc_test_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = gb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lor = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "lor.fit(X_train, y_train)\n",
    "#predicting the target value from the model for the samples\n",
    "y_test_lor = lor.predict(X_test)\n",
    "y_train_lor = lor.predict(X_train)\n",
    "acc_train_lor = accuracy_score(y_train,y_train_lor)\n",
    "acc_test_lor = accuracy_score(y_test,y_test_lor)\n",
    "\n",
    "print(\"Logistic Regression: Accuracy on training Data: {:.3f}\".format(acc_train_lor))\n",
    "print(\"Logistic Regression : Accuracy on test Data: {:.3f}\".format(acc_test_lor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lor = lor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#majority voting\n",
    "\n",
    "y_test_maj = []\n",
    "for i in range(y_test_xgb.size):\n",
    "    y_maj=[]\n",
    "    y_maj.append(y_test_xgb[i])\n",
    "    y_maj.append(y_test_tree[i])\n",
    "    y_maj.append(y_test_forest[i])\n",
    "    #y_maj.append(y_test_ada[i])\n",
    "    y_maj.append(y_test_mlp[i])\n",
    "    #y_maj.append(y_test_cat[i])\n",
    "    y_maj.append(y_test_lor[i])\n",
    "    #y_maj.append(y_test_gb[i])\n",
    "    a = y_maj.count(1)\n",
    "    b = y_maj.count(0)\n",
    "    mode=y_test_xgb[i]\n",
    "    if a>b:\n",
    "        mode=1\n",
    "    elif b>a:\n",
    "        mode=0\n",
    "    y_test_maj.append(mode)\n",
    "test_acc_score_maj1 = accuracy_score(y_test, y_test_maj)\n",
    "test_acc_score_maj2 = precision_score(y_test, y_test_maj)\n",
    "test_acc_score_maj3 = recall_score(y_test, y_test_maj)\n",
    "test_acc_score_maj4 = f1_score(y_test, y_test_maj)\n",
    "test_acc_score_maj5 = roc_auc_score(y_test, y_test_maj)\n",
    "print(\"Majority Voting : Accuracy on testing Data: {:.3f}\".format(test_acc_score_maj1))\n",
    "print(\"Majority Voting : Precision on testing Data: {:.3f}\".format(test_acc_score_maj2))\n",
    "print(\"Majority Voting : Recall on testing Data: {:.3f}\".format(test_acc_score_maj3))\n",
    "print(\"Majority Voting : F1 on testing Data: {:.3f}\".format(test_acc_score_maj4))\n",
    "print(\"Majority Voting : AUC-ROC on testing Data: {:.3f}\".format(test_acc_score_maj5))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Phishing Website Detection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
