{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/peyamowar/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peyamowar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/peyamowar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import scipy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from google_trans_new import google_translator  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "gloveFile = \"glove.6B.200d.txt\"\n",
    "translator = google_translator()  \n",
    "model = loadGloveModel(gloveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(s1, s2):\n",
    "    #cosine_distance_countvectorizer_method\n",
    "    # sentences to list\n",
    "    allsentences = [s1 , s2]\n",
    "    # text to vector\n",
    "    vectorizer = CountVectorizer()\n",
    "    all_sentences_to_vector = vectorizer.fit_transform(allsentences)\n",
    "    text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()\n",
    "    text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()\n",
    "    # distance of similarity\n",
    "    cosine = distance.cosine(text_to_vector_v1, text_to_vector_v2)\n",
    "    #print('Similarity of two sentences are equal to ',round((1-cosine)*100,2),'%')\n",
    "    return round((1-cosine)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw_text):\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "    return cleaned_words\n",
    "\n",
    "def cosine_distance_between_two_words(word1, word2):\n",
    "    import scipy\n",
    "    return (1- scipy.spatial.distance.cosine(model[word1], model[word2]))\n",
    "\n",
    "def func2(s1, s2):\n",
    "    #cosine_distance_wordembedding_method\n",
    "    vector_1 = np.mean([model[word] for word in preprocess(s1) if word in model],axis=0)\n",
    "    #print(\"vector 1\")\n",
    "    #print(vector_1)\n",
    "    #print(type(vector_1))\n",
    "    vector_2 = np.mean([model[word] for word in preprocess(s2) if word in model],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    #print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1-cosine)*100,2),'%')\n",
    "    return round((1-cosine)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3(s1,s2):\n",
    "    #cosine_similarity method\n",
    "    X = s1\n",
    "    Y = s2\n",
    "    # tokenization \n",
    "    X_list = word_tokenize(X) \n",
    "    Y_list = word_tokenize(Y) \n",
    "    # sw contains the list of stopwords \n",
    "    sw = stopwords.words('english') \n",
    "    l1 =[];l2 =[] \n",
    "    # remove stop words from the string \n",
    "    X_set = {w for w in X_list if not w in sw} \n",
    "    Y_set = {w for w in Y_list if not w in sw} \n",
    "    # form a set containing keywords of both strings \n",
    "    rvector = X_set.union(Y_set) \n",
    "    for w in rvector: \n",
    "        if w in X_set: l1.append(1) # create a vector \n",
    "        else: l1.append(0) \n",
    "        if w in Y_set: l2.append(1) \n",
    "        else: l2.append(0) \n",
    "    c = 0\n",
    "    # cosine formula \n",
    "    for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "    deno = float((sum(l1)*sum(l2))**0.5) \n",
    "    if deno == 0:\n",
    "        return 50\n",
    "    cosine = c / deno\n",
    "    return round((1-cosine)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.81\n",
      "73.72\n",
      "83.1\n"
     ]
    }
   ],
   "source": [
    "s1 = \"The president of USA gives a speech in Chicago.\"\n",
    "s2 = \"Obama addresses public in Illinois.\"\n",
    "\n",
    "text1 = translator.translate(s1,lang_tgt='en')\n",
    "text2 = translator.translate(s2,lang_tgt='en')\n",
    "\n",
    "print(func1(text1,text2))\n",
    "print(func2(text1,text2))\n",
    "print(func3(text1,text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data3 = data1.append(data2)\n",
    "data3 = data3.drop(columns={'Unnamed: 0'})\n",
    "data3.to_csv('bollybait_audio_text_till_283.csv',index=False)\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data1 = pd.read_csv('bollybait_audio_text_till_283.csv')\n",
    "#data2 = pd.read_csv('bollybait_audio_text_till_921.csv')\n",
    "#data3 = pd.read_csv('bollybait_audio_text_till_end.csv')\n",
    "#data = data1.append(data2)\n",
    "#data = data.append(data3)\n",
    "data = pd.read_csv('audio_text_mvd.csv')\n",
    "data = data.drop(columns={'Unnamed: 0'})\n",
    "#data.to_csv('bollybait_audio_text.csv')\n",
    "source_data = pd.read_csv(\"MVD_dataset_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>to8mQVw1Lso</td>\n",
       "      <td>hello friends friends Abhi Abhi Bollywood se b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4N3hPrJLbEw</td>\n",
       "      <td>power couple Aishwarya Rai Bachchan Abhishek B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CfvUr6WAEWM</td>\n",
       "      <td>everybody wants to use simple easy steps to ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i1rlytoxQ1o</td>\n",
       "      <td>Johny Secrets of the Bachchan family you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>jkytlp91onQ</td>\n",
       "      <td>filmwise of bollywood celebrities sutapa sikda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4jZ-7xhLj-w</td>\n",
       "      <td>good evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>L2rPcFB-bKg</td>\n",
       "      <td>Pappu Kyon Nahin tumne mujhe bataya Tumhare Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>EPq2r8hUCBM</td>\n",
       "      <td>England ki Maharani ka darbar Mein Swagat hai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>gPuxJYAuT_g</td>\n",
       "      <td>weather Sahab aap soch rahe Honge aap 154 Lagt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>DHJaC6tArpY</td>\n",
       "      <td>Tere Munh per</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Video_id                                               Text\n",
       "0    to8mQVw1Lso  hello friends friends Abhi Abhi Bollywood se b...\n",
       "1    4N3hPrJLbEw  power couple Aishwarya Rai Bachchan Abhishek B...\n",
       "2    CfvUr6WAEWM  everybody wants to use simple easy steps to ge...\n",
       "3    i1rlytoxQ1o  Johny Secrets of the Bachchan family you know ...\n",
       "4    jkytlp91onQ  filmwise of bollywood celebrities sutapa sikda...\n",
       "..           ...                                                ...\n",
       "674  4jZ-7xhLj-w                                       good evening\n",
       "675  L2rPcFB-bKg  Pappu Kyon Nahin tumne mujhe bataya Tumhare Pa...\n",
       "676  EPq2r8hUCBM  England ki Maharani ka darbar Mein Swagat hai ...\n",
       "677  gPuxJYAuT_g  weather Sahab aap soch rahe Honge aap 154 Lagt...\n",
       "678  DHJaC6tArpY                                      Tere Munh per\n",
       "\n",
       "[679 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sad News For Dharmendra Fans, Dharmendra Death...</td>\n",
       "      <td>to8mQVw1Lso</td>\n",
       "      <td>Clickbait</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Dharmendra Death</td>\n",
       "      <td>rxTuq8gymc0</td>\n",
       "      <td>Clickbait</td>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Abhishek Bachchan and Shweta Bachchan in Koffe...</td>\n",
       "      <td>4N3hPrJLbEw</td>\n",
       "      <td>Clickbait</td>\n",
       "      <td>celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>How To Get 6 Pack Abs In One Day</td>\n",
       "      <td>CfvUr6WAEWM</td>\n",
       "      <td>Clickbait</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Dirty Secrets of the Bachchan Family</td>\n",
       "      <td>i1rlytoxQ1o</td>\n",
       "      <td>Clickbait</td>\n",
       "      <td>celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>987</td>\n",
       "      <td>Aishwarya accepts ‘Khajur’ as her son – The Ka...</td>\n",
       "      <td>mu1LmpE_rjE</td>\n",
       "      <td>Real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>988</td>\n",
       "      <td>Cold War Between Lottery And Sarla - The Kapil...</td>\n",
       "      <td>L2rPcFB-bKg</td>\n",
       "      <td>Real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>989</td>\n",
       "      <td>England Queen's Wedding Shopping | Sargun Meht...</td>\n",
       "      <td>EPq2r8hUCBM</td>\n",
       "      <td>Real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>Kapil Copies Dr. Gulati's Look - The Kapil Sha...</td>\n",
       "      <td>gPuxJYAuT_g</td>\n",
       "      <td>Real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>Rajesh Arora Hates Rinku's Face - The Kapil Sh...</td>\n",
       "      <td>DHJaC6tArpY</td>\n",
       "      <td>Real</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title     video_id  \\\n",
       "0    Sad News For Dharmendra Fans, Dharmendra Death...  to8mQVw1Lso   \n",
       "1                                     Dharmendra Death  rxTuq8gymc0   \n",
       "2    Abhishek Bachchan and Shweta Bachchan in Koffe...  4N3hPrJLbEw   \n",
       "3                     How To Get 6 Pack Abs In One Day  CfvUr6WAEWM   \n",
       "4                 Dirty Secrets of the Bachchan Family  i1rlytoxQ1o   \n",
       "..                                                 ...          ...   \n",
       "987  Aishwarya accepts ‘Khajur’ as her son – The Ka...  mu1LmpE_rjE   \n",
       "988  Cold War Between Lottery And Sarla - The Kapil...  L2rPcFB-bKg   \n",
       "989  England Queen's Wedding Shopping | Sargun Meht...  EPq2r8hUCBM   \n",
       "990  Kapil Copies Dr. Gulati's Look - The Kapil Sha...  gPuxJYAuT_g   \n",
       "991  Rajesh Arora Hates Rinku's Face - The Kapil Sh...  DHJaC6tArpY   \n",
       "\n",
       "         LABEL      Topic  \n",
       "0    Clickbait      Death  \n",
       "1    Clickbait      Death  \n",
       "2    Clickbait  celebrity  \n",
       "3    Clickbait     Health  \n",
       "4    Clickbait  celebrity  \n",
       "..         ...        ...  \n",
       "987       Real        NaN  \n",
       "988       Real        NaN  \n",
       "989       Real        NaN  \n",
       "990       Real        NaN  \n",
       "991       Real        NaN  \n",
       "\n",
       "[992 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n"
     ]
    }
   ],
   "source": [
    "video_id = list()\n",
    "title_audio_sim_1 = list()\n",
    "title_audio_sim_2 = list()\n",
    "title_audio_sim_3 = list()\n",
    "\n",
    "i = 0\n",
    "for ind, row in data.iterrows():\n",
    "    s1 = row['Text'].lower()\n",
    "    i = i + 1\n",
    "    print(i)\n",
    "        #text1 = translator.translate(s1,lang_tgt='en')\n",
    "    text1 = s1\n",
    "    ind_title = source_data[source_data['video_id']==row['Video_id']].index.values\n",
    "    s2 = source_data['Title'][ind_title[0]]\n",
    "    text2 = s2\n",
    "        #text2 = translator.translate(s2,lang_tgt='en')\n",
    "    val1 = func1(text1,text2)\n",
    "    val2 = func2(text1,text2)\n",
    "    val3 = func3(text1,text2)\n",
    "    video_id.append(row['Video_id'])\n",
    "    title_audio_sim_1.append(val1)\n",
    "    title_audio_sim_2.append(val2)\n",
    "    title_audio_sim_3.append(val3)\n",
    "    \n",
    "dict = {'Video ID' : video_id, 'Title vs Audio 1' : title_audio_sim_1, 'Title vs Audio 2' : title_audio_sim_2, 'Title vs Audio 3' : title_audio_sim_3}\n",
    "newdf = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv(\"audio_vs_title_mvd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Title vs Audio 1</th>\n",
       "      <th>Title vs Audio 2</th>\n",
       "      <th>Title vs Audio 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>to8mQVw1Lso</td>\n",
       "      <td>15.10</td>\n",
       "      <td>37.75</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4N3hPrJLbEw</td>\n",
       "      <td>22.34</td>\n",
       "      <td>46.02</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CfvUr6WAEWM</td>\n",
       "      <td>42.87</td>\n",
       "      <td>86.51</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i1rlytoxQ1o</td>\n",
       "      <td>33.81</td>\n",
       "      <td>64.38</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>jkytlp91onQ</td>\n",
       "      <td>25.93</td>\n",
       "      <td>79.27</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>674</td>\n",
       "      <td>4jZ-7xhLj-w</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.54</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>L2rPcFB-bKg</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>676</td>\n",
       "      <td>EPq2r8hUCBM</td>\n",
       "      <td>6.92</td>\n",
       "      <td>19.64</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>gPuxJYAuT_g</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>678</td>\n",
       "      <td>DHJaC6tArpY</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.81</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Video ID  Title vs Audio 1  Title vs Audio 2  Title vs Audio 3\n",
       "0    to8mQVw1Lso             15.10             37.75             100.0\n",
       "1    4N3hPrJLbEw             22.34             46.02             100.0\n",
       "2    CfvUr6WAEWM             42.87             86.51             100.0\n",
       "3    i1rlytoxQ1o             33.81             64.38             100.0\n",
       "4    jkytlp91onQ             25.93             79.27             100.0\n",
       "..           ...               ...               ...               ...\n",
       "674  4jZ-7xhLj-w              0.00             20.54             100.0\n",
       "675  L2rPcFB-bKg              0.00             -5.78             100.0\n",
       "676  EPq2r8hUCBM              6.92             19.64             100.0\n",
       "677  gPuxJYAuT_g              0.00              1.46             100.0\n",
       "678  DHJaC6tArpY              0.00              2.81             100.0\n",
       "\n",
       "[679 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('audio_vs_title_bollybait_1.csv')\n",
    "data2 = pd.read_csv('audio_vs_title_bollybait_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Title vs Audio 1</th>\n",
       "      <th>Title vs Audio 2</th>\n",
       "      <th>Title vs Audio 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>zR8x5FAvlPU</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.97</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>STL-ueSScRI</td>\n",
       "      <td>11.18</td>\n",
       "      <td>60.82</td>\n",
       "      <td>86.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>bJ-1QOOett0</td>\n",
       "      <td>16.12</td>\n",
       "      <td>44.79</td>\n",
       "      <td>89.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>qfr0NUD3FTU</td>\n",
       "      <td>8.13</td>\n",
       "      <td>29.83</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D_TP0L-s4V0</td>\n",
       "      <td>36.51</td>\n",
       "      <td>56.19</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>883</td>\n",
       "      <td>tOWpOL4ZgSw</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.27</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>884</td>\n",
       "      <td>MBrAY6GgU5k</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.94</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>owPuQjInzO8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.69</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>Es2bli0uSYY</td>\n",
       "      <td>7.40</td>\n",
       "      <td>47.90</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>FgHKdoYpGpI</td>\n",
       "      <td>6.90</td>\n",
       "      <td>54.64</td>\n",
       "      <td>91.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Video ID  Title vs Audio 1  Title vs Audio 2  Title vs Audio 3\n",
       "0    zR8x5FAvlPU              0.00              1.97            100.00\n",
       "1    STL-ueSScRI             11.18             60.82             86.52\n",
       "2    bJ-1QOOett0             16.12             44.79             89.34\n",
       "3    qfr0NUD3FTU              8.13             29.83            100.00\n",
       "4    D_TP0L-s4V0             36.51             56.19            100.00\n",
       "..           ...               ...               ...               ...\n",
       "883  tOWpOL4ZgSw              0.00             52.27            100.00\n",
       "884  MBrAY6GgU5k              0.00             44.94            100.00\n",
       "885  owPuQjInzO8              0.00             12.69            100.00\n",
       "886  Es2bli0uSYY              7.40             47.90            100.00\n",
       "887  FgHKdoYpGpI              6.90             54.64             91.09\n",
       "\n",
       "[888 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data1.append(data2)\n",
    "data = data.drop(columns={'Unnamed: 0'})\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"audio_vs_title_bollybait.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
